{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d1a570-6af1-439a-bd55-dffa269cf217",
   "metadata": {},
   "source": [
    "# modisLandsat - notebook to calibrate and upload hierarchical random forests for Landsat LAI and fAPAR based on MODIS algorithms\n",
    "\n",
    "## richard.fernandes@canada.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921523d-631b-4984-8636-b078ecade6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc72c34e-2146-4843-803c-9c4e33117063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python modules \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_text\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ffcab16-ca38-4cfa-9a6b-03d6673fc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct hierarchal random forests for FTL method\n",
    "def hierarchicalRF(dataDictParent,dataDictChild,regressorsNames,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=20, maxDepthChild=20, minSamplesSplit=11,maxleafnodesParent= 100, minSamplesLeafParent=10, maxleafnodesChild= 999, minSamplesLeafChild=10,maxFeatures=\"auto\",nTrees = 100):\n",
    "    \n",
    "    \n",
    "    # make generic names for regressors for use in GEE\n",
    "    regressors = []\n",
    "    for item in np.arange(1,len(regressorsNames)+1,1):\n",
    "        regressors.append('x' + str(item))\n",
    "\n",
    "    # Calibrate hierarchal randforest preeidctors for each biome\n",
    "    for biome in dataDictParent.keys() : \n",
    "        print('biome:',biome)\n",
    "\n",
    "        # subset only the regressors and response \n",
    "        dfBiome = dataDictChild[biome]['DF'][sum([regressorsNames,response],[])].astype('int')   \n",
    "        dfParent = dataDictParent[biome]['DF'][sum([regressorsNames,response],[])].astype('int')\n",
    "\n",
    "\n",
    "        dfBiome.columns = sum([regressors,response],[])\n",
    "        dfParent.columns = sum([regressors,response],[])\n",
    "        print('Total size ',dfBiome.shape)\n",
    "        print('Parent size ',dfParent.shape)\n",
    "         # populate a parent RF dictionary that holds a single tree RF used to partition data into child RFs\n",
    "        parentRFDict = {}\n",
    "        parentRFDict.update({'regressors': regressors})\n",
    "        parentRFDict.update({'regressorsGEE': regressorsGEENames})\n",
    "        parentRFDict.update({'response': response})\n",
    "        parentRFDict.update({'domain':makeDomain(dfBiome[regressors],domainIndex,domainScaling,domainOffset)})\n",
    "        parentRFDict.update({'RF': RandomForestRegressor(n_estimators=1,min_samples_leaf=minSamplesLeafParent,min_samples_split=minSamplesSplit,bootstrap=False,random_state=0,verbose=0,max_depth=maxDepthParent,max_leaf_nodes=maxleafnodesParent,max_features=maxFeatures,n_jobs=40) \\\n",
    "                                                                                                         .fit(dfParent[regressors], np.array(dfParent[response]).ravel())})         \n",
    "        # label input data using the prediction from the parent RF as this will be unique\n",
    "        dfBiome['estimate']=np.around(np.array(parentRFDict['RF'].predict(dfBiome[regressors])),decimals=3)\n",
    "\n",
    "        # populate dictionary of children RFs, each childRF is itself a dictionary similar to the parentRF but now using more than one tree\n",
    "        # each child is labelled using the prediction value from the parentRF corresponding to its partition\n",
    "        childrenRFDict = {}\n",
    "        print('number children:',np.unique(np.around(np.array(parentRFDict['RF'].predict(dfBiome[regressors])),decimals=3)).size)\n",
    "        for partition in np.unique(np.around(np.array(parentRFDict['RF'].predict(dfBiome[regressors])),decimals=3)):\n",
    "            dfpartitionBiome = dfBiome.loc[dfBiome['estimate'] == partition]\n",
    "            childRFDict = {}\n",
    "            childRFDict.update({'size': dfpartitionBiome[response].shape[0]})\n",
    "            childRFDict.update({'regressors': regressors})\n",
    "            childRFDict.update({'regressorsGEE': regressorsGEENames})\n",
    "            childRFDict.update({'response': response})\n",
    "            childRFDict.update({'domain':makeDomain(dfpartitionBiome[regressors],domainIndex,domainScaling,domainOffset)})\n",
    "            childRFDict.update({'RF': RandomForestRegressor(n_estimators=nTrees,min_samples_leaf=minSamplesLeafChild,bootstrap=True,random_state=0,verbose=0,max_depth=maxDepthChild,max_leaf_nodes=maxleafnodesChild,max_features=maxFeatures,n_jobs=40) \\\n",
    "                                     .fit(dfpartitionBiome[regressors], np.array(dfpartitionBiome[response]).ravel())})             \n",
    "            childrenRFDict.update({partition: childRFDict})\n",
    "\n",
    "        # assign the childrenRFDict to the parent\n",
    "        parentRFDict.update({'childrenRFDict':childrenRFDict })      \n",
    "\n",
    "        #assign the parentRF dict to the calibration data dictionary for trhis biome\n",
    "        dataDictParent[biome].update({method+response[0]+'parentRFDict':parentRFDict})   \n",
    "    return dataDictParent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e583b6a-dd5a-4549-b696-5135d56e332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code the input feature domain by using a linear hash for each row of the input data frame\n",
    "#the hash algorithm converts each input row into an integer from 0 to 9 by applying the provided scale and offset and then rounding\n",
    "#is then produces a hash entry for each row by packing the integers consequitively to form a uint64 code\n",
    "#this implies a limit of at most 18 columns for the input data frame\n",
    "#returns a list corresonding to hash table of unique coded input rows\n",
    "def makeDomain(df,domainIndex,domainScaling,domainOffset):\n",
    "    df = np.array(df) \n",
    "    if df.shape[1] < 19 :\n",
    "        domainIndex = np.array(domainIndex)\n",
    "        domainScaling = np.array(domainScaling)\n",
    "        domainOffset = np.array(domainOffset)\n",
    "    else:\n",
    "        raise ValueError(\"More than 18 dimensions in domain\")\n",
    "    return np.uint64(np.unique(np.sum(np.clip(np.around(df* domainScaling + domainOffset,0),0,9) * np.power(10,np.cumsum(domainIndex)-domainIndex[0]),1),0)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c4adcf1-0fe3-485c-b0de-8a635c6af61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse a sckitlearn decision tree into a R text tree suitable for use in GEE\n",
    "# for compactness ancillary items like node sample size and residuals are forced to = 1\n",
    "# this is a blind guess by Richard but seems to work\n",
    "def make_tree(rf,regressors,maxdepth,decimals):\n",
    "    \n",
    "    # first get the output in sckitlearn text format in a dataframe\n",
    "    r = export_text(decision_tree=rf,feature_names=regressors,show_weights=True,decimals=decimals,max_depth=depth)\n",
    "    r = r.splitlines()\n",
    "    rdf = pd.DataFrame(r,columns = ['rule'])\n",
    "\n",
    "    #identify rules and not leaf values\n",
    "    isrule = ~rdf['rule'].str.contains('value')\n",
    "    rulesdf = rdf.loc[isrule]\n",
    "\n",
    "    #determine level in tree and the associated starting based node number\n",
    "    rdf['level'] = rdf['rule'].str.count(r'(\\|)').values.tolist()\n",
    "    rdf.loc[isrule,'base'] = ((rdf.level).mul(0).add(2)).pow(rdf.level)\n",
    "\n",
    "    # get the actual tested condition\n",
    "    rdf.loc[isrule,'condition'] =  rdf.loc[isrule,'rule'].str.extract(r'(x.+)').values.tolist()\n",
    "    \n",
    "    # identify leaf nodes and fill in the response value\n",
    "    rdf.loc[~isrule,'leaf'] = '*'\n",
    "    rdf['leaf'] = rdf['leaf'].fillna(method='bfill',limit=1)\n",
    "    rdf.loc[~isrule,'response'] = rdf.loc[~isrule,'rule'].str.extract(r'([+-]?([0-9]*[.])?[0-9]+)')[0].values.tolist()\n",
    "    rdf['response'] = rdf['response'].fillna(method='bfill')\n",
    "\n",
    "    #discard non rules\n",
    "    rdf.loc[rdf['leaf'].isna(),'leaf'] = ' '\n",
    "    rdf = rdf.dropna()\n",
    "\n",
    "    #dtermine if this is a left or right branch\n",
    "    rdf['branch'] = rdf['rule'].str.contains(r'(?:\\>)').astype('int')\n",
    "    rdf['node'] = rdf.base + rdf.branch\n",
    "    rdf.loc[rdf.level==1,'node']=rdf.loc[rdf.level==1,'branch'] + 2\n",
    "    rdfindex = rdf.index\n",
    "\n",
    "    #asign a node number, this is non trivial and critical for use later\n",
    "    #read https://www.r-bloggers.com/2022/10/understanding-leaf-node-numbers-when-using-rpart-and-rpart-rules/\n",
    "    for row in range(2,rdf.shape[0]):\n",
    "        # find the nearest row above\n",
    "        df = rdf[0:row]\n",
    "        if ( (rdf[row:row+1].level.values)[0] > 1 ):\n",
    "            parentdf = df.loc[df.level == (rdf[row:row+1].level.values-1)[0]].iloc[-1]\n",
    "            rdf.at[rdfindex[row],'parentbase'] = parentdf.base  \n",
    "            rdf.at[rdfindex[row],'parentnode'] = parentdf.node  \n",
    "            rdf.at[rdfindex[row],'node'] = rdf.iloc[row].node + 2 * (  parentdf.node - parentdf.base ) \n",
    "            \n",
    "    # glue together each rule in a big string, add the root node and return as a list\n",
    "    rdf['phrase'] = rdf.apply(lambda x:  ' ' *(2 * x.level) + str(int(x.node)) + ') ' + x.condition + ' 0 0 ' + str(x.response) + ' ' +x.leaf + '\\n', axis=1)\n",
    "    return ( '1) root 1 1 1 (1)\\n'+''.join(rdf['phrase'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ecd79a-bd41-4b79-84f9-5fff442afa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was taken from the GEEMAP libraries and modified as needed here\n",
    "def export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,responseGEEScaling,responseGEEOffset,regressorsGEEScaling2, \\\n",
    "                            regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,asset_id,description=\"geemap_rf_export\"):\n",
    "\n",
    "    \"\"\"Function that creates a feature collection with a property tree which contains the string representation of decision trees and exports to ee asset for later use\n",
    "        together with CCRS tree properties\n",
    "    args:\n",
    "        trees (list[str]): list of string representation of the decision trees\n",
    "        response (str): name of response variable\n",
    "        regressors (list[str]): list pf strings of names of regressors variables in the created trees\n",
    "        regressorsGEECollectionName (str) : name of GEE input collection\n",
    "        regressorsGEENames (list[str]): list of names of the regressors variables in the GEE input collection\n",
    "      \tresponseGEEScaling (list[float]): list of scaling values to apply to GEE output image\n",
    "        responseGEEOffset (list[float]): list of  offset values to apply to GEE output image\n",
    "        regressorsGEEScaling2 (list[float]): list of scaling values to apply to GEE input collection after initial scale ad offset is applied\n",
    "        regressorsGEEScaling (list[float]): list of scaling values to apply to GEE input collection\n",
    "        regressorsGEEOffset (list[float]): list of  offset values to apply to GEE input collection\n",
    "        domain (list[uint64]): list of domain code values\n",
    "        domainScaling (list[float]) : list of scaling values to create domain\n",
    "        domainOffset ( list[float]): list of offset values to create domain\n",
    "        asset_id (str): ee asset id path to export the feature collection to\n",
    "\n",
    "\n",
    "    kwargs:\n",
    "        description (str): optional description to provide export information. default = \"geemap_rf_export\"\n",
    "\n",
    "    \"\"\"\n",
    "    # create a null geometry point. This is needed to properly export the feature collection\n",
    "    null_island = ee.Geometry.Point([0, 0])\n",
    "\n",
    "    # create a list of feature over null island\n",
    "    # set the tree property as the tree string\n",
    "    # encode return values (\\n) as #, use to parse later\n",
    "\n",
    "    \n",
    "    features = [\n",
    "        ee.Feature(null_island, {\"tree\": tree.replace(\"\\n\", \"#\"),\\\n",
    "                                 \"response\": ','.join(response),\\\n",
    "                                 \"regressors\": ','.join(regressors),\\\n",
    "                                 \"regressorsGEECollectionName\":regressorsGEECollectionName,\\\n",
    "                                 \"regressorsGENames\": ','.join(regressorsGEENames),\\\n",
    "                                 \"responseGEScaling\": ','.join(str(x) for x in responseGEEScaling),\\\n",
    "                                 \"responseGEOffset\": ','.join(str(x) for x in responseGEEOffset),\\\n",
    "                                 \"regressorsGEScaling2\": ','.join(str(x) for x in regressorsGEEScaling2),\\\n",
    "                                 \"regressorsGEScaling\": ','.join(str(x) for x in regressorsGEEScaling),\\\n",
    "                                 \"regressorsGEOffset\": ','.join(str(x) for x in regressorsGEEOffset),\\\n",
    "                                 # \"domain\": ','.join(str(x) for x in domain),\\\n",
    "                                 \"domainScaling\": ','.join(str(x) for x in domainScaling),\\\n",
    "                                 \"domainOffset\": ','.join(str(x) for x in domainOffset)} ) for tree in trees]\n",
    "    \n",
    "    # cast as feature collection\n",
    "    fc = ee.FeatureCollection(features)\n",
    "\n",
    "    # get export task and start\n",
    "    task = ee.batch.Export.table.toAsset(\n",
    "        collection=fc, description=description, assetId=asset_id\n",
    "    )\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5696a199-25e2-4b8a-b50d-0358aee825e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strings_to_classifier(trees=None,outputMode='REGRESSION'):\n",
    "    \"\"\"Function that takes string representation of decision trees and creates a ee.Classifier that can be used with ee objects\n",
    "\n",
    "    args:\n",
    "        trees (list[str]): list of string representation of the decision trees\n",
    "        outputMode [str] : classifier output mode\n",
    "    returns:\n",
    "        classifier (ee.Classifier): ee classifier object representing an ensemble decision tree\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # convert strings to ee.String objects\n",
    "    ee_strings = [ee.String(tree) for tree in trees]\n",
    "\n",
    "    # pass list of ee.Strings to an ensemble decision tree classifier (i.e. RandomForest)\n",
    "    classifier = ee.Classifier.decisionTreeEnsemble(ee_strings).setOutputMode(outputMode)\n",
    "\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b43ac-d427-496a-a51d-0069a6a2a735",
   "metadata": {},
   "source": [
    "# Read in calibration dictionaries\n",
    "## There are separate dictionaries for Saturated and UnSaturated samples for each of LAI and FAPAR and for the naive algorithm and the FTL algorithm\n",
    "## Each dictionary contains one key per biome number \n",
    "## Each biome has a dictionary that at minimum includes a key \"DF\" that corresponds to the calibration data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6023bf2e-0071-4114-9824-20fdfc32656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in calibration dictionaries\n",
    "# There are separate dictionaries for Saturated and UnSaturated samples for each of LAI and FAPAR and for the naive algorithm and the FTL algorithm\n",
    "# Each dictionary contains one key per biome number \n",
    "# Each biome has a dictionary that at minimum includes a key \"DF\" that corresponds to the calibration data \n",
    "calbiomeDictLAINAIVESat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAINAIVESat.pkl')\n",
    "calbiomeDictLAINAIVEUnSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAINAIVEUnSat.pkl')\n",
    "calbiomeDictLAIFTLSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAIFTLSat.pkl')\n",
    "calbiomeDicLAIFTLUnSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAIFTLUnSat.pkl')\n",
    "calbiomeDictLAIFTL2Sat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAIFTL2Sat.pkl')\n",
    "calbiomeDictLAIFTL2UnSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAIFTL2UnSat.pkl')\n",
    "\n",
    "calbiomeDictFAPARNAIVESat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARNAIVESat.pkl')\n",
    "calbiomeDictFAPARNAIVEUnSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARNAIVEUnSat.pkl')\n",
    "calbiomeDictFAPARFTLSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARFTLSat.pkl')\n",
    "calbiomeDictFAPARFTLUnSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARFTLUnSat.pkl')\n",
    "calbiomeDictFAPARFTL2Sat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARFTL2Sat.pkl')\n",
    "calbiomeDictFAPARFTL2UnSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARFTL2UnSat.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cce6a6-bf91-4599-9c81-e66fe633c150",
   "metadata": {},
   "source": [
    "# Calibrate biome specific Hierarichal RF models and save as a new key in the associated dictionary for each biome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef76dd-368a-41a4-8a63-d34a94103b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FTLSat LAI\n",
    "method = 'FTLSat'\n",
    "regressors = ['red','NIR','cosSZA','cosVZA','cosSA']\n",
    "response = ['LAI']\n",
    "\n",
    "# Stuff for GEE\n",
    "#Specify scaling and index for Domain, currently we only allow one digit per regressor\n",
    "# Number of digits per regressor\n",
    "domainIndex = [1,1,1,1,1]\n",
    "\n",
    "# Scaling per regressor\n",
    "domainScaling = [ 10/10000, 10/10000,10/10000,10/10000,10/10000]\n",
    "\n",
    "# Offset per regressor\n",
    "domainOffset = [ 0,0,0,0,0]\n",
    "\n",
    "#GEE regressor names\n",
    "regressorsGEENames =  [ 'SR_B4', 'SR_B5','cosSZA','cosVZA','cosSA'] \n",
    "\n",
    "#Calibrate the Hierarchical RF\n",
    "calbiomeDictLAIFTLSat= hierarchicalRF(calbiomeDictLAIFTLSat,calbiomeDictLAINAIVESat,regressors,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=20,maxDepthChild=20,minSamplesSplit=2,\\\n",
    "                             maxleafnodesParent=999,  minSamplesLeafParent=1000,maxleafnodesChild= 999, minSamplesLeafChild=1,maxFeatures=4,nTrees = 100)\n",
    "\n",
    "# Run this if you want to check the predictions\n",
    "# calbiomeDictLAIFTLSat=  predictClassifier(calbiomeDictLAIFTLSat,calbiomeDictLAIFTLSat, 'FTLSat', regressors, ['LAI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e120f-f9a7-487b-8c01-ec501798f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FTLUnSat LAI\n",
    "method = 'FTLUnSat'\n",
    "regressors = ['red','NIR','cosSZA','cosVZA','cosSA']\n",
    "response = ['LAI']\n",
    "\n",
    "# Stuff for GEE\n",
    "#Specify scaling and index for Domain, currently we only allow one digit per regressor\n",
    "# Number of digits per regressor\n",
    "domainIndex = [1,1,1,1,1]\n",
    "\n",
    "# Scaling per regressor\n",
    "domainScaling = [ 10/10000, 10/10000,10/10000,10/10000,10/10000]\n",
    "\n",
    "# Offset per regressor\n",
    "domainOffset = [ 0,0,0,0,0]\n",
    "\n",
    "#GEE regressor names\n",
    "regressorsGEENames =  [ 'SR_B4', 'SR_B5','cosSZA','cosVZA','cosSA'] \n",
    "\n",
    "#Calibrate the Hierarchical RF\n",
    "calbiomeDictLAIFTLUnSat= hierarchicalRF(calbiomeDictLAIFTLUnSat,calbiomeDictLAINAIVEUnSat,regressors,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=20,maxDepthChild=20,minSamplesSplit=2,\\\n",
    "                             maxleafnodesParent=999,  minSamplesLeafParent=1000,maxleafnodesChild= 999, minSamplesLeafChild=1,maxFeatures=4,nTrees = 100)\n",
    "\n",
    "# Run this if you want to check the predictions\n",
    "# calbiomeDictLAIFTLUnSat=  predictClassifier(calbiomeDictLAIFTLUnSat,calbiomeDictLAIFTLUnSat, 'FTLUnSat', regressors, ['LAI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86e2d1-0540-4148-aa70-ba322023b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FTLSat FAPAR\n",
    "method = 'FTLSat'\n",
    "regressors = ['red','NIR','cosSZA','cosVZA','cosSA']\n",
    "response = ['FAPAR']\n",
    "\n",
    "# Stuff for GEE\n",
    "#Specify scaling and index for Domain, currently we only allow one digit per regressor\n",
    "# Number of digits per regressor\n",
    "domainIndex = [1,1,1,1,1]\n",
    "\n",
    "# Scaling per regressor\n",
    "domainScaling = [ 10/10000, 10/10000,10/10000,10/10000,10/10000]\n",
    "\n",
    "# Offset per regressor\n",
    "domainOffset = [ 0,0,0,0,0]\n",
    "\n",
    "#GEE regressor names\n",
    "regressorsGEENames =  [ 'SR_B4', 'SR_B5','cosSZA','cosVZA','cosSA'] \n",
    "\n",
    "#Calibrate the Hierarchical RF\n",
    "calbiomeDictFAPARFTLSat= hierarchicalRF(calbiomeDictFAPARFTLSat,calbiomeDictFAPARNAIVESat,regressors,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=20,maxDepthChild=20,minSamplesSplit=2,\\\n",
    "                             maxleafnodesParent=999,  minSamplesLeafParent=1000,maxleafnodesChild= 999, minSamplesLeafChild=1,maxFeatures=4,nTrees = 100)\n",
    "\n",
    "# Run this if you want to check the predictions\n",
    "# calbiomeDictFAPARFTLSat=  predictClassifier(calbiomeDictFAPARFTLSat,calbiomeDictFAPARFTLSat, 'FTLSat', regressors, ['FAPAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a3207-25f5-491e-9a3d-694db5eeb7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FTLUnSat FAPAR\n",
    "method = 'FTLUnSat'\n",
    "regressors = ['red','NIR','cosSZA','cosVZA','cosSA']\n",
    "response = ['FAPAR']\n",
    "\n",
    "# Stuff for GEE\n",
    "#Specify scaling and index for Domain, currently we only allow one digit per regressor\n",
    "# Number of digits per regressor\n",
    "domainIndex = [1,1,1,1,1]\n",
    "\n",
    "# Scaling per regressor\n",
    "domainScaling = [ 10/10000, 10/10000,10/10000,10/10000,10/10000]\n",
    "\n",
    "# Offset per regressor\n",
    "domainOffset = [ 0,0,0,0,0]\n",
    "\n",
    "#GEE regressor names\n",
    "regressorsGEENames =  [ 'SR_B4', 'SR_B5','cosSZA','cosVZA','cosSA'] \n",
    "\n",
    "#Calibrate the Hierarchical RF\n",
    "calbiomeDictFAPARFTLUnSat= hierarchicalRF(calbiomeDictFAPARUnFTLSat,calbiomeDictFAPARNAIVEUnSat,regressors,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=20,maxDepthChild=20,minSamplesSplit=2,\\\n",
    "                             maxleafnodesParent=999,  minSamplesLeafParent=1000,maxleafnodesChild= 999, minSamplesLeafChild=1,maxFeatures=4,nTrees = 100)\n",
    "\n",
    "# Run this if you want to check the predictions\n",
    "# calbiomeDictFAPARFTLUnSat=  predictClassifier(calbiomeDictFAPARFTLUnSat,calbiomeDictFAPARFTLUnSat, 'FTLUnSat', regressors, ['FAPAR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15854b84-47ad-45b3-b848-2efc811a7e68",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Upload trees to GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d70102-ff53-468f-b993-3abebfe58d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224440c4-9cdf-4701-abe6-ade858807d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67ea71-dbc9-4605-839f-aca062e438f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload FTL classiers to gee as feature collections\n",
    "method = 'FTL'\n",
    "\n",
    "# response variable name\n",
    "response = ['LAI']\n",
    "targetDirectory = '/FTL_trees_LAI/'\n",
    "methodDict = calbiomeDictLAIFTL\n",
    "\n",
    "# Scaling and offset required of GEE regressors\n",
    "regressorsGEECollectionName= \"LANDSAT/LC08/C02/T1_L2\"\n",
    "regressorsGEEScaling = [2.75e-05,2.75e-05,1,1,1]\n",
    "regressorsGEEOffset = [-0.02,-0.02,0,0,0]\n",
    "regressorsGEEScaling2 = [10000,10000,1,1,1]\n",
    "responseGEEScaling = [10]\n",
    "responseGEEOffset = [0]\n",
    "\n",
    "for biome in [1,2,3,4,5,6,7,8]:\n",
    "    print('biome', biome)\n",
    "    parentRFDict = methodDict[biome][method+response[0]+'parentRFDict']\n",
    "    domain = parentRFDict['domain']\n",
    "    trees = []\n",
    "    trees.append(make_tree(parentRFDict['RF'][0],regressors,3))\n",
    "    print('# of children', len(parentRFDict['childrenRFDict']))\n",
    "    assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'parentRF' \n",
    "    export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,responseGEEScaling,responseGEEOffset,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "    ee_classifier = strings_to_classifier(trees)\n",
    "    print(ee_classifier.getInfo())\n",
    "\n",
    "    childSize = []\n",
    "    for partition in parentRFDict['childrenRFDict'].keys():\n",
    "        print('child #', partition)\n",
    "        childRFDict = parentRFDict['childrenRFDict'][partition]\n",
    "        childSize.append(childRFDict['size'])\n",
    "        trees = []\n",
    "        for tree in np.squeeze(childRFDict['RF'].estimators_) :\n",
    "            trees.append(make_tree(tree,regressors,3))\n",
    "        assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'childRF' + str(int(partition*1000)) \n",
    "        domain = [0]\n",
    "        domainScaling = [0]\n",
    "        domainOffset = [0]\n",
    "        mlLocal.export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "        # ee_classifier = strings_to_classifier(trees)\n",
    "        # print(ee_classifier.getInfo())\n",
    "    print(childSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8bbba0-04ef-4e36-9eae-1674c06edd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload FTL classiers to gee as feature collections\n",
    "method = 'FTLSat'\n",
    "\n",
    "# response variable name\n",
    "response = ['LAI']\n",
    "targetDirectory = '/FTL_trees_LAI_Sat/'\n",
    "methodDict = calbiomeDictLAIFTLSAT\n",
    "\n",
    "# Scaling and offset required of GEE regressors\n",
    "regressorsGEECollectionName= \"LANDSAT/LC08/C02/T1_L2\"\n",
    "regressorsGEEScaling = [2.75e-05,2.75e-05,1,1,1]\n",
    "regressorsGEEOffset = [-0.02,-0.02,0,0,0]\n",
    "regressorsGEEScaling2 = [10000,10000,10000,10000,10000]\n",
    "responseGEEScaling = [10]\n",
    "responseGEEOffset = [0]\n",
    "\n",
    "for biome in [1,2,3,4,5,6,7,8]:\n",
    "    print('biome', biome)\n",
    "    parentRFDict = methodDict[biome][method+response[0]+'parentRFDict']\n",
    "    domain = parentRFDict['domain']\n",
    "    trees = []\n",
    "    trees.append(make_tree(parentRFDict['RF'][0],regressors,3))\n",
    "    print('# of children', len(parentRFDict['childrenRFDict']))\n",
    "    assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'parentRF' \n",
    "    export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,responseGEEScaling,responseGEEOffset,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "    ee_classifier = strings_to_classifier(trees)\n",
    "    print(ee_classifier.getInfo())\n",
    "\n",
    "    childSize = []\n",
    "    for partition in parentRFDict['childrenRFDict'].keys():\n",
    "        print('child #', partition)\n",
    "        childRFDict = parentRFDict['childrenRFDict'][partition]\n",
    "        childSize.append(childRFDict['size'])\n",
    "        trees = []\n",
    "        for tree in np.squeeze(childRFDict['RF'].estimators_) :\n",
    "            trees.append(make_tree(tree,regressors,3))\n",
    "        assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'childRF' + str(int(partition*1000)) \n",
    "        domain = [0]\n",
    "        domainScaling = [0]\n",
    "        domainOffset = [0]\n",
    "        mlLocal.export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "        # ee_classifier = strings_to_classifier(trees)\n",
    "        # print(ee_classifier.getInfo())\n",
    "    print(childSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2682f1c-07d5-4512-93ed-f5f8d74cfe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload FTL classiers to gee as feature collections\n",
    "method = 'FTLUNSat'\n",
    "\n",
    "# response variable name\n",
    "response = ['LAI']\n",
    "targetDirectory = '/FTL_trees_LAI_UNSat/'\n",
    "methodDict = calbiomeDictLAIFTLSAT\n",
    "\n",
    "# Scaling and offset required of GEE regressors\n",
    "regressorsGEECollectionName= \"LANDSAT/LC08/C02/T1_L2\"\n",
    "regressorsGEEScaling = [2.75e-05,2.75e-05,1,1,1]\n",
    "regressorsGEEOffset = [-0.02,-0.02,0,0,0]\n",
    "regressorsGEEScaling2 = [10000,10000,10000,10000,10000]\n",
    "responseGEEScaling = [10]\n",
    "responseGEEOffset = [0]\n",
    "\n",
    "for biome in [1,2,3,4,5,6,7,8]:\n",
    "    print('biome', biome)\n",
    "    parentRFDict = methodDict[biome][method+response[0]+'parentRFDict']\n",
    "    domain = parentRFDict['domain']\n",
    "    trees = []\n",
    "    trees.append(make_tree(parentRFDict['RF'][0],regressors,3))\n",
    "    print('# of children', len(parentRFDict['childrenRFDict']))\n",
    "    assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'parentRF' \n",
    "    export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,responseGEEScaling,responseGEEOffset,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "    ee_classifier = strings_to_classifier(trees)\n",
    "    print(ee_classifier.getInfo())\n",
    "\n",
    "    childSize = []\n",
    "    for partition in parentRFDict['childrenRFDict'].keys():\n",
    "        print('child #', partition)\n",
    "        childRFDict = parentRFDict['childrenRFDict'][partition]\n",
    "        childSize.append(childRFDict['size'])\n",
    "        trees = []\n",
    "        for tree in np.squeeze(childRFDict['RF'].estimators_) :\n",
    "            trees.append(make_tree(tree,regressors,3))\n",
    "        assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'childRF' + str(int(partition*1000)) \n",
    "        domain = [0]\n",
    "        domainScaling = [0]\n",
    "        domainOffset = [0]\n",
    "        mlLocal.export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "        # ee_classifier = strings_to_classifier(trees)\n",
    "        # print(ee_classifier.getInfo())\n",
    "    print(childSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63794c89-822d-4f1a-87e4-a447050b599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload FTL classiers to gee as feature collections\n",
    "method = 'FTLSat\n",
    "\n",
    "# response variable name\n",
    "response = ['FAPAR']\n",
    "targetDirectory = '/FTL_trees_FAPAR_Sat\n",
    "methodDict = calbiomeDictLAIFTLSAT\n",
    "\n",
    "# Scaling and offset required of GEE regressors\n",
    "regressorsGEECollectionName= \"LANDSAT/LC08/C02/T1_L2\"\n",
    "regressorsGEEScaling = [2.75e-05,2.75e-05,1,1,1]\n",
    "regressorsGEEOffset = [-0.02,-0.02,0,0,0]\n",
    "regressorsGEEScaling2 = [10000,10000,10000,10000,10000]\n",
    "responseGEEScaling = [100]\n",
    "responseGEEOffset = [0]\n",
    "\n",
    "for biome in [1,2,3,4,5,6,7,8]:\n",
    "    print('biome', biome)\n",
    "    parentRFDict = methodDict[biome][method+response[0]+'parentRFDict']\n",
    "    domain = parentRFDict['domain']\n",
    "    trees = []\n",
    "    trees.append(make_tree(parentRFDict['RF'][0],regressors,3))\n",
    "    print('# of children', len(parentRFDict['childrenRFDict']))\n",
    "    assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'parentRF' \n",
    "    export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,responseGEEScaling,responseGEEOffset,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "    # ee_classifier = strings_to_classifier(trees)\n",
    "    # print(ee_classifier.getInfo())\n",
    "\n",
    "    childSize = []\n",
    "    for partition in parentRFDict['childrenRFDict'].keys():\n",
    "        print('child #', partition)\n",
    "        childRFDict = parentRFDict['childrenRFDict'][partition]\n",
    "        childSize.append(childRFDict['size'])\n",
    "        trees = []\n",
    "        for tree in np.squeeze(childRFDict['RF'].estimators_) :\n",
    "            trees.append(make_tree(tree,regressors,3))\n",
    "        assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'childRF' + str(int(partition*1000)) \n",
    "        domain = [0]\n",
    "        domainScaling = [0]\n",
    "        domainOffset = [0]\n",
    "        mlLocal.export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "        # ee_classifier = strings_to_classifier(trees)\n",
    "        # print(ee_classifier.getInfo())\n",
    "    print(childSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d307d-1521-4a97-a8f7-18f1bd7ceeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload FTL classiers to gee as feature collections\n",
    "method = 'FTLUNSat'\n",
    "\n",
    "# response variable name\n",
    "response = ['FAPAR']\n",
    "targetDirectory = '/FTL_trees_FAPAR_UNSat/'\n",
    "methodDict = calbiomeDictLAIFTLSAT\n",
    "\n",
    "# Scaling and offset required of GEE regressors\n",
    "regressorsGEECollectionName= \"LANDSAT/LC08/C02/T1_L2\"\n",
    "regressorsGEEScaling = [2.75e-05,2.75e-05,1,1,1]\n",
    "regressorsGEEOffset = [-0.02,-0.02,0,0,0]\n",
    "regressorsGEEScaling2 = [10000,10000,10000,10000,10000]\n",
    "responseGEEScaling = [100]\n",
    "responseGEEOffset = [0]\n",
    "\n",
    "for biome in [1,2,3,4,5,6,7,8]:\n",
    "    print('biome', biome)\n",
    "    parentRFDict = methodDict[biome][method+response[0]+'parentRFDict']\n",
    "    domain = parentRFDict['domain']\n",
    "    trees = []\n",
    "    trees.append(make_tree(parentRFDict['RF'][0],regressors,3))\n",
    "    print('# of children', len(parentRFDict['childrenRFDict']))\n",
    "    assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'parentRF' \n",
    "    export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,responseGEEScaling,responseGEEOffset,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "    # ee_classifier = strings_to_classifier(trees)\n",
    "    # print(ee_classifier.getInfo())\n",
    "\n",
    "    childSize = []\n",
    "    for partition in parentRFDict['childrenRFDict'].keys():\n",
    "        print('child #', partition)\n",
    "        childRFDict = parentRFDict['childrenRFDict'][partition]\n",
    "        childSize.append(childRFDict['size'])\n",
    "        trees = []\n",
    "        for tree in np.squeeze(childRFDict['RF'].estimators_) :\n",
    "            trees.append(make_tree(tree,regressors,3))\n",
    "        assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'childRF' + str(int(partition*1000)) \n",
    "        domain = [0]\n",
    "        domainScaling = [0]\n",
    "        domainOffset = [0]\n",
    "        mlLocal.export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "        # ee_classifier = strings_to_classifier(trees)\n",
    "        # print(ee_classifier.getInfo())\n",
    "    print(childSize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
