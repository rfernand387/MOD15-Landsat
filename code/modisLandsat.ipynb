{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96d1a570-6af1-439a-bd55-dffa269cf217",
   "metadata": {
    "tags": []
   },
   "source": [
    "# modisLandsat - notebook to calibrate and upload hierarchical random forests for Landsat LAI and fAPAR based on MODIS algorithms\n",
    "\n",
    "## richard.fernandes@canada.ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c921523d-631b-4984-8636-b078ecade6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc72c34e-2146-4843-803c-9c4e33117063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# python modules \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import export_text\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import ee\n",
    "import geemap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ffcab16-ca38-4cfa-9a6b-03d6673fc941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# construct hierarchal random forests for FTL method\n",
    "def hierarchicalRF(dataDictParent,dataDictChild,regressorsNames,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=20, maxDepthChild=20, minSamplesSplit=11,maxleafnodesParent= 100, minSamplesLeafParent=10, maxleafnodesChild= 999, minSamplesLeafChild=10,maxFeatures=\"auto\",nTrees = 100):\n",
    "    \n",
    "    \n",
    "    # make generic names for regressors for use in GEE\n",
    "    regressors = []\n",
    "    for item in np.arange(1,len(regressorsNames)+1,1):\n",
    "        regressors.append('x' + str(item))\n",
    "\n",
    "    # Calibrate hierarchal randforest preeidctors for each biome\n",
    "    for biome in dataDictParent.keys() : \n",
    "        print('biome:',biome)\n",
    "\n",
    "        # subset only the regressors and response \n",
    "        dfBiome = dataDictChild[biome]['DF'][sum([regressorsNames,response],[])].astype('int')   \n",
    "        dfParent = dataDictParent[biome]['DF'][sum([regressorsNames,response],[])].astype('int')\n",
    "\n",
    "\n",
    "        dfBiome.columns = sum([regressors,response],[])\n",
    "        dfParent.columns = sum([regressors,response],[])\n",
    "        print('Total size ',dfBiome.shape)\n",
    "        print('Parent size ',dfParent.shape)\n",
    "         # populate a parent RF dictionary that holds a single tree RF used to partition data into child RFs\n",
    "        parentRFDict = {}\n",
    "        parentRFDict.update({'regressors': regressors})\n",
    "        parentRFDict.update({'regressorsGEE': regressorsGEENames})\n",
    "        parentRFDict.update({'response': response})\n",
    "        parentRFDict.update({'domain':makeDomain(dfBiome[regressors],domainIndex,domainScaling,domainOffset)})\n",
    "        parentRFDict.update({'RF': RandomForestRegressor(n_estimators=1,min_samples_leaf=minSamplesLeafParent,min_samples_split=minSamplesSplit,bootstrap=False,random_state=0,verbose=0,max_depth=maxDepthParent,max_leaf_nodes=maxleafnodesParent,max_features=maxFeatures,n_jobs=40) \\\n",
    "                                                                                                         .fit(dfParent[regressors], np.array(dfParent[response]).ravel())})         \n",
    "        # label input data using the prediction from the parent RF as this will be unique\n",
    "        dfBiome['estimate']=np.around(np.array(parentRFDict['RF'].predict(dfBiome[regressors])),decimals=3)\n",
    "\n",
    "        # populate dictionary of children RFs, each childRF is itself a dictionary similar to the parentRF but now using more than one tree\n",
    "        # each child is labelled using the prediction value from the parentRF corresponding to its partition\n",
    "        childrenRFDict = {}\n",
    "        print('number children:',np.unique(np.around(np.array(parentRFDict['RF'].predict(dfBiome[regressors])),decimals=3)).size)\n",
    "        for partition in np.unique(np.around(np.array(parentRFDict['RF'].predict(dfBiome[regressors])),decimals=3)):\n",
    "            dfpartitionBiome = dfBiome.loc[dfBiome['estimate'] == partition]\n",
    "            childRFDict = {}\n",
    "            childRFDict.update({'size': dfpartitionBiome[response].shape[0]})\n",
    "            childRFDict.update({'regressors': regressors})\n",
    "            childRFDict.update({'regressorsGEE': regressorsGEENames})\n",
    "            childRFDict.update({'response': response})\n",
    "            childRFDict.update({'domain':makeDomain(dfpartitionBiome[regressors],domainIndex,domainScaling,domainOffset)})\n",
    "            childRFDict.update({'RF': RandomForestRegressor(n_estimators=nTrees,min_samples_leaf=minSamplesLeafChild,bootstrap=True,random_state=0,verbose=0,max_depth=maxDepthChild,max_leaf_nodes=maxleafnodesChild,max_features=maxFeatures,n_jobs=40) \\\n",
    "                                     .fit(dfpartitionBiome[regressors], np.array(dfpartitionBiome[response]).ravel())})             \n",
    "            childrenRFDict.update({partition: childRFDict})\n",
    "\n",
    "        # assign the childrenRFDict to the parent\n",
    "        parentRFDict.update({'childrenRFDict':childrenRFDict })      \n",
    "\n",
    "        #assign the parentRF dict to the calibration data dictionary for trhis biome\n",
    "        dataDictParent[biome].update({method+response[0]+'parentRFDict':parentRFDict})   \n",
    "    return dataDictParent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f389f349-ce06-4012-be55-44591094e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply algorithm to data \n",
    "def predictClassifier(dataDict,methodDict, method, regressorsNames, response):\n",
    "    # make generic names for regressors for use in GEE\n",
    "    regressors = []\n",
    "    for item in np.arange(1,len(regressorsNames)+1,1):\n",
    "        regressors.append('x' + str(item))\n",
    "\n",
    "    # Calibrate hierarchal randforest preeidctors for each biome\n",
    "    for biome in dataDict.keys():\n",
    "\n",
    "        print('biome:',biome)\n",
    "\n",
    "        if ( biome in [1,2,4,6,7]):\n",
    "            # subset only the regressors \n",
    "            dfBiome = dataDict[biome]['DF'][sum([regressorsNames],[])].astype('int')\n",
    "            dfBiome.columns = regressors\n",
    "\n",
    "            #apply the parent classifier\n",
    "            parentRF = methodDict[biome][method+response[0]+'parentRFDict']['RF']\n",
    "            dfBiome['childNames'] =  np.around(parentRF.predict(dfBiome),decimals=3)\n",
    "            dataDict[biome]['DF'][method + response[0]+'childNames'] =dfBiome['childNames']\n",
    "\n",
    "            for partition in np.unique(dfBiome['childNames'] ):\n",
    "                dfBiome.loc[dfBiome['childNames']==partition,method + response[0]] = methodDict[biome][method+response[0]+'parentRFDict']['childrenRFDict'][partition]['RF'].predict(dfBiome.loc[dfBiome['childNames']==partition][regressors])  \n",
    "            dataDict[biome]['DF'][method + response[0]] = dfBiome[method + response[0]]\n",
    "           \n",
    "    return dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e583b6a-dd5a-4549-b696-5135d56e332e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#code the input feature domain by using a linear hash for each row of the input data frame\n",
    "#the hash algorithm converts each input row into an integer from 0 to 9 by applying the provided scale and offset and then rounding\n",
    "#is then produces a hash entry for each row by packing the integers consequitively to form a uint64 code\n",
    "#this implies a limit of at most 18 columns for the input data frame\n",
    "#returns a list corresonding to hash table of unique coded input rows\n",
    "def makeDomain(df,domainIndex,domainScaling,domainOffset):\n",
    "    df = np.array(df) \n",
    "    if df.shape[1] < 19 :\n",
    "        domainIndex = np.array(domainIndex)\n",
    "        domainScaling = np.array(domainScaling)\n",
    "        domainOffset = np.array(domainOffset)\n",
    "    else:\n",
    "        raise ValueError(\"More than 18 dimensions in domain\")\n",
    "    return np.uint64(np.unique(np.sum(np.clip(np.around(df* domainScaling + domainOffset,0),0,9) * np.power(10,np.cumsum(domainIndex)-domainIndex[0]),1),0)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c4adcf1-0fe3-485c-b0de-8a635c6af61e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parse a sckitlearn decision tree into a R text tree suitable for use in GEE\n",
    "# for compactness ancillary items like node sample size and residuals are forced to = 1\n",
    "# this is a blind guess by Richard but seems to work\n",
    "def make_tree(rf,regressors,decimals=3,maxDepth=20):\n",
    "    \n",
    "    # first get the output in sckitlearn text format in a dataframe\n",
    "    r = export_text(decision_tree=rf,feature_names=regressors,show_weights=True,decimals=decimals,max_depth=maxDepth)\n",
    "    r = r.splitlines()\n",
    "    rdf = pd.DataFrame(r,columns = ['rule'])\n",
    "    \n",
    "    #identify rules and not leaf values\n",
    "    isrule = ~rdf['rule'].str.contains('value')\n",
    "    rulesdf = rdf.loc[isrule]\n",
    "    \n",
    "    #determine level in tree and the associated starting based node number\n",
    "    rdf['level'] = rdf['rule'].str.count(r'(\\|)').values.tolist()\n",
    "    rdf.loc[isrule,'base'] = ((rdf.level).mul(0).add(2)).pow(rdf.level)\n",
    "\n",
    "    # get the actual tested condition\n",
    "    rdf.loc[isrule,'condition'] =  rdf.loc[isrule,'rule'].str.extract(r'(x.+)').values.tolist()\n",
    "    \n",
    "    # identify leaf nodes and fill in the response value\n",
    "    rdf.loc[~isrule,'leaf'] = '*'\n",
    "    rdf['leaf'] = rdf['leaf'].fillna(method='bfill',limit=1)\n",
    "    rdf.loc[~isrule,'response'] = rdf.loc[~isrule,'rule'].str.extract(r'([+-]?([0-9]*[.])?[0-9]+)')[0].values.tolist()\n",
    "    rdf['response'] = rdf['response'].fillna(method='bfill')\n",
    "    \n",
    "    #discard non rules\n",
    "    rdf.loc[rdf['leaf'].isna(),'leaf'] = ' '\n",
    "    rdf = rdf.dropna()\n",
    "\n",
    "    #dtermine if this is a left or right branch\n",
    "    rdf['branch'] = rdf['rule'].str.contains(r'(?:\\>)').astype('int')\n",
    "    rdf['node'] = rdf.base + rdf.branch\n",
    "    rdf.loc[rdf.level==1,'node']=rdf.loc[rdf.level==1,'branch'] + 2\n",
    "    rdfindex = rdf.index\n",
    "    \n",
    "    #asign a node number, this is non trivial and critical for use later\n",
    "    #read https://www.r-bloggers.com/2022/10/understanding-leaf-node-numbers-when-using-rpart-and-rpart-rules/\n",
    "    for row in range(2,rdf.shape[0]):\n",
    "        # find the nearest row above\n",
    "        df = rdf[0:row]\n",
    "        if ( (rdf[row:row+1].level.values)[0] > 1 ):\n",
    "            parentdf = df.loc[df.level == (rdf[row:row+1].level.values-1)[0]].iloc[-1]\n",
    "            rdf.at[rdfindex[row],'parentbase'] = parentdf.base  \n",
    "            rdf.at[rdfindex[row],'parentnode'] = parentdf.node  \n",
    "            rdf.at[rdfindex[row],'node'] = rdf.iloc[row].node + 2 * (  parentdf.node - parentdf.base ) \n",
    "    \n",
    "    # glue together each rule in a big string, add the root node and return as a list\n",
    "    rdf['phrase'] = rdf.apply(lambda x:  ' ' *(2 * x.level) + str(int(x.node)) + ') ' + x.condition + ' 0 0 ' + str(x.response) + ' ' +x.leaf + '\\n', axis=1)\n",
    "    return ( '1) root 1 1 1 (1)\\n'+''.join(rdf['phrase'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8ecd79a-bd41-4b79-84f9-5fff442afa77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function was taken from the GEEMAP libraries and modified as needed here\n",
    "def export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,responseGEEScaling,responseGEEOffset,regressorsGEEScaling2, \\\n",
    "                            regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,asset_id,description=\"geemap_rf_export\"):\n",
    "\n",
    "    \"\"\"Function that creates a feature collection with a property tree which contains the string representation of decision trees and exports to ee asset for later use\n",
    "        together with CCRS tree properties\n",
    "    args:\n",
    "        trees (list[str]): list of string representation of the decision trees\n",
    "        response (str): name of response variable\n",
    "        regressors (list[str]): list pf strings of names of regressors variables in the created trees\n",
    "        regressorsGEECollectionName (str) : name of GEE input collection\n",
    "        regressorsGEENames (list[str]): list of names of the regressors variables in the GEE input collection\n",
    "      \tresponseGEEScaling (list[float]): list of scaling values to apply to GEE output image\n",
    "        responseGEEOffset (list[float]): list of  offset values to apply to GEE output image\n",
    "        regressorsGEEScaling2 (list[float]): list of scaling values to apply to GEE input collection after initial scale ad offset is applied\n",
    "        regressorsGEEScaling (list[float]): list of scaling values to apply to GEE input collection\n",
    "        regressorsGEEOffset (list[float]): list of  offset values to apply to GEE input collection\n",
    "        domain (list[uint64]): list of domain code values\n",
    "        domainScaling (list[float]) : list of scaling values to create domain\n",
    "        domainOffset ( list[float]): list of offset values to create domain\n",
    "        asset_id (str): ee asset id path to export the feature collection to\n",
    "\n",
    "\n",
    "    kwargs:\n",
    "        description (str): optional description to provide export information. default = \"geemap_rf_export\"\n",
    "\n",
    "    \"\"\"\n",
    "    # create a null geometry point. This is needed to properly export the feature collection\n",
    "    null_island = ee.Geometry.Point([0, 0])\n",
    "\n",
    "    # create a list of feature over null island\n",
    "    # set the tree property as the tree string\n",
    "    # encode return values (\\n) as #, use to parse later\n",
    "\n",
    "    \n",
    "    features = [\n",
    "        ee.Feature(null_island, {\"tree\": tree.replace(\"\\n\", \"#\"),\\\n",
    "                                 \"response\": ','.join(response),\\\n",
    "                                 \"regressors\": ','.join(regressors),\\\n",
    "                                 \"regressorsGEECollectionName\":regressorsGEECollectionName,\\\n",
    "                                 \"regressorsGENames\": ','.join(regressorsGEENames),\\\n",
    "                                 \"responseGEScaling\": ','.join(str(x) for x in responseGEEScaling),\\\n",
    "                                 \"responseGEOffset\": ','.join(str(x) for x in responseGEEOffset),\\\n",
    "                                 \"regressorsGEScaling2\": ','.join(str(x) for x in regressorsGEEScaling2),\\\n",
    "                                 \"regressorsGEScaling\": ','.join(str(x) for x in regressorsGEEScaling),\\\n",
    "                                 \"regressorsGEOffset\": ','.join(str(x) for x in regressorsGEEOffset),\\\n",
    "                                 # \"domain\": ','.join(str(x) for x in domain),\\\n",
    "                                 \"domainScaling\": ','.join(str(x) for x in domainScaling),\\\n",
    "                                 \"domainOffset\": ','.join(str(x) for x in domainOffset)} ) for tree in trees]\n",
    "    \n",
    "    # cast as feature collection\n",
    "    fc = ee.FeatureCollection(features)\n",
    "\n",
    "    # get export task and start\n",
    "    task = ee.batch.Export.table.toAsset(\n",
    "        collection=fc, description=description, assetId=asset_id\n",
    "    )\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5696a199-25e2-4b8a-b50d-0358aee825e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strings_to_classifier(trees=None,outputMode='REGRESSION'):\n",
    "    \"\"\"Function that takes string representation of decision trees and creates a ee.Classifier that can be used with ee objects\n",
    "\n",
    "    args:\n",
    "        trees (list[str]): list of string representation of the decision trees\n",
    "        outputMode [str] : classifier output mode\n",
    "    returns:\n",
    "        classifier (ee.Classifier): ee classifier object representing an ensemble decision tree\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # convert strings to ee.String objects\n",
    "    ee_strings = [ee.String(tree) for tree in trees]\n",
    "\n",
    "    # pass list of ee.Strings to an ensemble decision tree classifier (i.e. RandomForest)\n",
    "    classifier = ee.Classifier.decisionTreeEnsemble(ee_strings).setOutputMode(outputMode)\n",
    "\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b4409de-35af-49ab-884e-93e72ad38475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all intercomaprison feature collections\n",
    "def get_asset_list(parent):\n",
    "    parent_asset = ee.data.getAsset(parent)\n",
    "    parent_id = parent_asset['name']\n",
    "    parent_type = parent_asset['type']\n",
    "    asset_list = []\n",
    "    child_assets = ee.data.listAssets({'parent': parent_id})['assets']\n",
    "    for child_asset in child_assets:\n",
    "        child_id = child_asset['name']\n",
    "        child_type = child_asset['type']\n",
    "        if child_type in ['FOLDER','IMAGE_COLLECTION']:\n",
    "            # Recursively call the function to get child assets\n",
    "            asset_list.extend(get_asset_list(child_id))\n",
    "        else:\n",
    "            asset_list.append(child_id)\n",
    "    return asset_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b43ac-d427-496a-a51d-0069a6a2a735",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Read in calibration dictionaries\n",
    "## There are separate dictionaries for Saturated and UnSaturated samples for each of LAI and FAPAR and for the naive algorithm and the FTL algorithm\n",
    "## Each dictionary contains one key per biome number \n",
    "## Each biome has a dictionary that at minimum includes a key \"DF\" that corresponds to the calibration data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6023bf2e-0071-4114-9824-20fdfc32656f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in calibration dictionaries found at https://drive.google.com/drive/folders/1fpU0jCLiMVPKqkES8kqRw40jGP38uKmp\n",
    "# There are separate dictionaries for Saturated and UnSaturated samples for each of LAI and FAPAR and for the naive algorithm and the FTL algorithm\n",
    "# Each dictionary contains one key per biome number \n",
    "# Each biome has a dictionary that at minimum includes a key \"DF\" that corresponds to the calibration data \n",
    "calbiomeDictLAINAIVE= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAINAIVE.pkl')\n",
    "calbiomeDictLAIFTL= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAIFTLdf.pkl')\n",
    "\n",
    "# The dictionarys below will eventually be used but are not currently available\n",
    "\n",
    "# calbiomeDictLAINAIVESat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAINAIVESat.pkl')\n",
    "# calbiomeDictLAINAIVEUnSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAINAIVEUnSat.pkl')\n",
    "# calbiomeDictLAIFTLSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAIFTLSat.pkl')\n",
    "# calbiomeDicLAIFTLUnSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictLAIFTLUnSat.pkl')\n",
    "\n",
    "calbiomeDictFAPARNAIVE= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARNAIVE.pkl')\n",
    "calbiomeDictFAPARFTL= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARFTLdf.pkl')\n",
    "\n",
    "# calbiomeDictFAPARNAIVESat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARNAIVESat.pkl')\n",
    "# calbiomeDictFAPARNAIVEUnSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARNAIVEUnSat.pkl')\n",
    "# calbiomeDictFAPARFTLSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARFTLSat.pkl')\n",
    "# calbiomeDictFAPARFTLUnSat= pd.read_pickle('c:/users/rfernand/modisLandsat/code/calbiomeDictFAPARFTLUnSat.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cce6a6-bf91-4599-9c81-e66fe633c150",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calibrate biome specific Hierarichal RF models and save as a new key in the associated dictionary for each biome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c3be38-d818-4e87-a912-ded7c1955990",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calibrate RF for all samples (includes both saturated and unsaturated together) - This is the current implemented solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0da30ad0-cd97-4b7c-b250-6a6cf8755a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biome: 2\n",
      "biome: 1\n",
      "biome: 9\n",
      "biome: 4\n",
      "biome: 6\n",
      "biome: 7\n",
      "biome: 8\n",
      "biome: 3\n",
      "biome: 5\n",
      "biome: 10\n"
     ]
    }
   ],
   "source": [
    "# FTL LAI\n",
    "method = 'FTL'\n",
    "regressors = ['red','NIR','cosSZA','cosVZA','cosSA']\n",
    "response = ['LAI']\n",
    "\n",
    "# Stuff for GEE\n",
    "#Specify scaling and index for Domain, currently we only allow one digit per regressor\n",
    "# Number of digits per regressor\n",
    "domainIndex = [1,1,1,1,1]\n",
    "\n",
    "# Scaling per regressor\n",
    "domainScaling = [ 10/10000, 10/10000,10/10000,10/10000,10/10000]\n",
    "\n",
    "# Offset per regressor\n",
    "domainOffset = [ 0,0,0,0,0]\n",
    "\n",
    "#GEE regressor names\n",
    "regressorsGEENames =  [ 'SR_B4', 'SR_B5','cosSZA','cosVZA','cosSA'] \n",
    "\n",
    "# Calibrate the Hierarchical RF\n",
    "calbiomeDictLAIFTL= hierarchicalRF(calbiomeDictLAIFTL,calbiomeDictLAINAIVE,regressors,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=10,maxDepthChild=10,minSamplesSplit=2,\\\n",
    "                             maxleafnodesParent=9,  minSamplesLeafParent=1000,maxleafnodesChild= 999, minSamplesLeafChild=1,maxFeatures=4,nTrees = 100)\n",
    "\n",
    "# Run this if you want to check the predictions\n",
    "calbiomeDictLAIFTL=  predictClassifier(calbiomeDictLAIFTL,calbiomeDictLAIFTL, 'FTL', regressors, ['LAI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1603555e-ae76-4561-9934-2ca9e217cd83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biome: 2\n",
      "Total size  (484803, 6)\n",
      "Parent size  (11815, 6)\n",
      "number children: 9\n",
      "biome: 1\n",
      "Total size  (2358491, 6)\n",
      "Parent size  (52030, 6)\n",
      "number children: 9\n",
      "biome: 9\n",
      "Total size  (19139, 6)\n",
      "Parent size  (3533, 6)\n",
      "number children: 3\n",
      "biome: 4\n",
      "Total size  (1767949, 6)\n",
      "Parent size  (10323, 6)\n",
      "number children: 8\n",
      "biome: 6\n",
      "Total size  (541660, 6)\n",
      "Parent size  (4230, 6)\n",
      "number children: 3\n",
      "biome: 7\n",
      "Total size  (376649, 6)\n",
      "Parent size  (3409, 6)\n",
      "number children: 3\n",
      "biome: 8\n",
      "Total size  (60805, 6)\n",
      "Parent size  (4747, 6)\n",
      "number children: 3\n",
      "biome: 3\n",
      "Total size  (260189, 6)\n",
      "Parent size  (5322, 6)\n",
      "number children: 4\n",
      "biome: 5\n",
      "Total size  (215478, 6)\n",
      "Parent size  (4232, 6)\n",
      "number children: 3\n",
      "biome: 10\n",
      "Total size  (2183, 6)\n",
      "Parent size  (2183, 6)\n",
      "number children: 2\n"
     ]
    }
   ],
   "source": [
    "# FTL FAPAR\n",
    "method = 'FTL'\n",
    "regressors = ['red','NIR','cosSZA','cosVZA','cosSA']\n",
    "response = ['FAPAR']\n",
    "\n",
    "# Stuff for GEE\n",
    "#Specify scaling and index for Domain, currently we only allow one digit per regressor\n",
    "# Number of digits per regressor\n",
    "domainIndex = [1,1,1,1,1]\n",
    "\n",
    "# Scaling per regressor\n",
    "domainScaling = [ 10/10000, 10/10000,10/10000,10/10000,10/10000]\n",
    "\n",
    "# Offset per regressor\n",
    "domainOffset = [ 0,0,0,0,0]\n",
    "\n",
    "#GEE regressor names\n",
    "regressorsGEENames =  [ 'SR_B4', 'SR_B5','cosSZA','cosVZA','cosSA'] \n",
    "\n",
    "#Calibrate the Hierarchical RF\n",
    "calbiomeDictFAPARFTL= hierarchicalRF(calbiomeDictFAPARFTL,calbiomeDictFAPARNAIVE,regressors,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=20,maxDepthChild=20,minSamplesSplit=2,\\\n",
    "                             maxleafnodesParent=9,  minSamplesLeafParent=1000,maxleafnodesChild= 999, minSamplesLeafChild=1,maxFeatures=4,nTrees = 100)\n",
    "\n",
    "# Run this if you want to check the predictions\n",
    "# calbiomeDictFAPARFTL=  predictClassifier(calbiomeDictFAPARFTL,calbiomeDictFAPARFTLSat, 'FTLSat', regressors, ['FAPAR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cd684d-2d1b-4f5b-b703-80695fa1ccd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calibrate Saturated and Unsaturated RFs - Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef76dd-368a-41a4-8a63-d34a94103b94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# FTLSat LAI\n",
    "method = 'FTLSat'\n",
    "regressors = ['red','NIR','cosSZA','cosVZA','cosSA']\n",
    "response = ['LAI']\n",
    "\n",
    "# Stuff for GEE\n",
    "#Specify scaling and index for Domain, currently we only allow one digit per regressor\n",
    "# Number of digits per regressor\n",
    "domainIndex = [1,1,1,1,1]\n",
    "\n",
    "# Scaling per regressor\n",
    "domainScaling = [ 10/10000, 10/10000,10/10000,10/10000,10/10000]\n",
    "\n",
    "# Offset per regressor\n",
    "domainOffset = [ 0,0,0,0,0]\n",
    "\n",
    "#GEE regressor names\n",
    "regressorsGEENames =  [ 'SR_B4', 'SR_B5','cosSZA','cosVZA','cosSA'] \n",
    "\n",
    "#Calibrate the Hierarchical RF\n",
    "calbiomeDictLAIFTLSat= hierarchicalRF(calbiomeDictLAIFTLSat,calbiomeDictLAINAIVESat,regressors,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=20,maxDepthChild=20,minSamplesSplit=2,\\\n",
    "                             maxleafnodesParent=999,  minSamplesLeafParent=1000,maxleafnodesChild= 999, minSamplesLeafChild=1,maxFeatures=4,nTrees = 100)\n",
    "\n",
    "# Run this if you want to check the predictions\n",
    "# calbiomeDictLAIFTLSat=  predictClassifier(calbiomeDictLAIFTLSat,calbiomeDictLAIFTLSat, 'FTLSat', regressors, ['LAI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e120f-f9a7-487b-8c01-ec501798f5fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# FTLUnSat LAI\n",
    "method = 'FTLUnSat'\n",
    "regressors = ['red','NIR','cosSZA','cosVZA','cosSA']\n",
    "response = ['LAI']\n",
    "\n",
    "# Stuff for GEE\n",
    "#Specify scaling and index for Domain, currently we only allow one digit per regressor\n",
    "# Number of digits per regressor\n",
    "domainIndex = [1,1,1,1,1]\n",
    "\n",
    "# Scaling per regressor\n",
    "domainScaling = [ 10/10000, 10/10000,10/10000,10/10000,10/10000]\n",
    "\n",
    "# Offset per regressor\n",
    "domainOffset = [ 0,0,0,0,0]\n",
    "\n",
    "#GEE regressor names\n",
    "regressorsGEENames =  [ 'SR_B4', 'SR_B5','cosSZA','cosVZA','cosSA'] \n",
    "\n",
    "#Calibrate the Hierarchical RF\n",
    "calbiomeDictLAIFTLUnSat= hierarchicalRF(calbiomeDictLAIFTLUnSat,calbiomeDictLAINAIVEUnSat,regressors,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=20,maxDepthChild=20,minSamplesSplit=2,\\\n",
    "                             maxleafnodesParent=999,  minSamplesLeafParent=1000,maxleafnodesChild= 999, minSamplesLeafChild=1,maxFeatures=4,nTrees = 100)\n",
    "\n",
    "# Run this if you want to check the predictions\n",
    "# calbiomeDictLAIFTLUnSat=  predictClassifier(calbiomeDictLAIFTLUnSat,calbiomeDictLAIFTLUnSat, 'FTLUnSat', regressors, ['LAI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86e2d1-0540-4148-aa70-ba322023b7d6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# FTLSat FAPAR\n",
    "method = 'FTLSat'\n",
    "regressors = ['red','NIR','cosSZA','cosVZA','cosSA']\n",
    "response = ['FAPAR']\n",
    "\n",
    "# Stuff for GEE\n",
    "#Specify scaling and index for Domain, currently we only allow one digit per regressor\n",
    "# Number of digits per regressor\n",
    "domainIndex = [1,1,1,1,1]\n",
    "\n",
    "# Scaling per regressor\n",
    "domainScaling = [ 10/10000, 10/10000,10/10000,10/10000,10/10000]\n",
    "\n",
    "# Offset per regressor\n",
    "domainOffset = [ 0,0,0,0,0]\n",
    "\n",
    "#GEE regressor names\n",
    "regressorsGEENames =  [ 'SR_B4', 'SR_B5','cosSZA','cosVZA','cosSA'] \n",
    "\n",
    "#Calibrate the Hierarchical RF\n",
    "calbiomeDictFAPARFTLSat= hierarchicalRF(calbiomeDictFAPARFTLSat,calbiomeDictFAPARNAIVESat,regressors,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=20,maxDepthChild=20,minSamplesSplit=2,\\\n",
    "                             maxleafnodesParent=999,  minSamplesLeafParent=1000,maxleafnodesChild= 999, minSamplesLeafChild=1,maxFeatures=4,nTrees = 100)\n",
    "\n",
    "# Run this if you want to check the predictions\n",
    "# calbiomeDictFAPARFTLSat=  predictClassifier(calbiomeDictFAPARFTLSat,calbiomeDictFAPARFTLSat, 'FTLSat', regressors, ['FAPAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a3207-25f5-491e-9a3d-694db5eeb7ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# FTLUnSat FAPAR\n",
    "method = 'FTLUnSat'\n",
    "regressors = ['red','NIR','cosSZA','cosVZA','cosSA']\n",
    "response = ['FAPAR']\n",
    "\n",
    "# Stuff for GEE\n",
    "#Specify scaling and index for Domain, currently we only allow one digit per regressor\n",
    "# Number of digits per regressor\n",
    "domainIndex = [1,1,1,1,1]\n",
    "\n",
    "# Scaling per regressor\n",
    "domainScaling = [ 10/10000, 10/10000,10/10000,10/10000,10/10000]\n",
    "\n",
    "# Offset per regressor\n",
    "domainOffset = [ 0,0,0,0,0]\n",
    "\n",
    "#GEE regressor names\n",
    "regressorsGEENames =  [ 'SR_B4', 'SR_B5','cosSZA','cosVZA','cosSA'] \n",
    "\n",
    "#Calibrate the Hierarchical RF\n",
    "calbiomeDictFAPARFTLUnSat= hierarchicalRF(calbiomeDictFAPARUnFTLSat,calbiomeDictFAPARNAIVEUnSat,regressors,regressorsGEENames, response, domainScaling,domainOffset, maxDepthParent=20,maxDepthChild=20,minSamplesSplit=2,\\\n",
    "                             maxleafnodesParent=999,  minSamplesLeafParent=1000,maxleafnodesChild= 999, minSamplesLeafChild=1,maxFeatures=4,nTrees = 100)\n",
    "\n",
    "# Run this if you want to check the predictions\n",
    "# calbiomeDictFAPARFTLUnSat=  predictClassifier(calbiomeDictFAPARFTLUnSat,calbiomeDictFAPARFTLUnSat, 'FTLUnSat', regressors, ['FAPAR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15854b84-47ad-45b3-b848-2efc811a7e68",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Upload trees to GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3d70102-ff53-468f-b993-3abebfe58d57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=kedRYsRYMB_o2zrn407iQPhDVCysnI7hibhAPaxeaDY&tc=AuirkFGz38LzxezSE9SJZgDJWcpaAuUk8ru1LtkEW2U&cc=8kUoWkzsPLQArUP_mHG0FQt2y-JFoXhHXCa8k8Y-J44>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=kedRYsRYMB_o2zrn407iQPhDVCysnI7hibhAPaxeaDY&tc=AuirkFGz38LzxezSE9SJZgDJWcpaAuUk8ru1LtkEW2U&cc=8kUoWkzsPLQArUP_mHG0FQt2y-JFoXhHXCa8k8Y-J44</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AWtgzh5jD4fCRb5yaX0IicByqAvBxuMVM1HW0y99SxucevGXl6ve7iiTxDs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "224440c4-9cdf-4701-abe6-ade858807d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f33746f-21cb-4ecf-a3a2-f19416034ac4",
   "metadata": {},
   "source": [
    "## Upload algiorithms based on combined saturated and unsaturated samples - this is the current implemented solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67ea71-dbc9-4605-839f-aca062e438f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biome 1\n",
      "# of children 9\n",
      "child # 4.363\n",
      "child # 6.597\n"
     ]
    }
   ],
   "source": [
    "# upload FTL classiers to gee as feature collections\n",
    "method = 'FTL'\n",
    "\n",
    "# response variable name\n",
    "response = ['LAI']\n",
    "targetDirectory = 'projects/ee-modis250/assets/FTL_trees_LAI/'\n",
    "methodDict = calbiomeDictLAIFTL\n",
    "regressors = [\"x1\",\"x2\",\"x3\",\"x4\",\"x5\"]\n",
    "\n",
    "# Scaling and offset required of GEE regressors\n",
    "regressorsGEECollectionName= \"LANDSAT/LC08/C02/T1_L2\"\n",
    "regressorsGEEScaling = [2.75e-05,2.75e-05,1,1,1]\n",
    "regressorsGEEOffset = [-0.02,-0.02,0,0,0]\n",
    "regressorsGEEScaling2 = [10000,10000,1,1,1]\n",
    "responseGEEScaling = [100]\n",
    "responseGEEOffset = [0]\n",
    "\n",
    "# parameters for parsing tree\n",
    "decimals = 3\n",
    "maxDepth = 10\n",
    "\n",
    "for biome in [1,2,3,4,5,6,7,8]:\n",
    "    print('biome', biome)\n",
    "    parentRFDict = methodDict[biome][method+response[0]+'parentRFDict']\n",
    "    domain = parentRFDict['domain']\n",
    "    trees = []\n",
    "    trees.append(make_tree(parentRFDict['RF'][0],regressors,decimals,maxDepth))\n",
    "    print('# of children', len(parentRFDict['childrenRFDict']))\n",
    "    assetID = targetDirectory + method + 'biome' + str(biome) + 'parentRF' \n",
    "    export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,responseGEEScaling,responseGEEOffset,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "    # ee_classifier = strings_to_classifier(trees)\n",
    "    # print(ee_classifier.getInfo())\n",
    "\n",
    "    childSize = []\n",
    "    for partition in parentRFDict['childrenRFDict'].keys():\n",
    "        print('child #', partition)\n",
    "        childRFDict = parentRFDict['childrenRFDict'][partition]\n",
    "        childSize.append(childRFDict['size'])\n",
    "        trees = []\n",
    "        for tree in np.squeeze(childRFDict['RF'].estimators_) :\n",
    "            trees.append(make_tree(tree,regressors,decimals,maxDepth))\n",
    "        assetID =  targetDirectory + method + 'biome' + str(biome) + 'childRF' + str(int(partition*1000)) \n",
    "        domain = [0]\n",
    "        domainScaling = [0]\n",
    "        domainOffset = [0]\n",
    "        export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,responseGEEScaling,responseGEEOffset,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "        # ee_classifier = strings_to_classifier(trees)\n",
    "        # print(ee_classifier.getInfo())\n",
    "    print(childSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b358691c-eb15-495c-b75c-5a8ffb275eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload FTL classiers to gee as feature collections\n",
    "method = 'FTL'\n",
    "\n",
    "# response variable name\n",
    "response = ['FAPAR']\n",
    "targetDirectory = '/FTL_trees_FAPAR/'\n",
    "methodDict = calbiomeDictLAIFTL\n",
    "\n",
    "# Scaling and offset required of GEE regressors\n",
    "regressorsGEECollectionName= \"LANDSAT/LC08/C02/T1_L2\"\n",
    "regressorsGEEScaling = [2.75e-05,2.75e-05,1,1,1]\n",
    "regressorsGEEOffset = [-0.02,-0.02,0,0,0]\n",
    "regressorsGEEScaling2 = [10000,10000,1,1,1]\n",
    "responseGEEScaling = [10]\n",
    "responseGEEOffset = [0]\n",
    "\n",
    "# parameters for parsing tree\n",
    "decimals = 3\n",
    "maxDepth = 20\n",
    "\n",
    "for biome in [1,2,3,4,5,6,7,8]:\n",
    "    print('biome', biome)\n",
    "    parentRFDict = methodDict[biome][method+response[0]+'parentRFDict']\n",
    "    domain = parentRFDict['domain']\n",
    "    trees = []\n",
    "    trees.append(make_tree(parentRFDict['RF'][0],regressors,decimals,maxDepth))\n",
    "    print('# of children', len(parentRFDict['childrenRFDict']))\n",
    "    assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'parentRF' \n",
    "    export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,responseGEEScaling,responseGEEOffset,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "    ee_classifier = strings_to_classifier(trees)\n",
    "    print(ee_classifier.getInfo())\n",
    "\n",
    "    childSize = []\n",
    "    for partition in parentRFDict['childrenRFDict'].keys():\n",
    "        print('child #', partition)\n",
    "        childRFDict = parentRFDict['childrenRFDict'][partition]\n",
    "        childSize.append(childRFDict['size'])\n",
    "        trees = []\n",
    "        for tree in np.squeeze(childRFDict['RF'].estimators_) :\n",
    "            trees.append(make_tree(tree,regressors,decimals.maxDepth))\n",
    "        assetID = geemap.ee_user_id() + targetDirectory + method + 'biome' + str(biome) + 'childRF' + str(int(partition*1000)) \n",
    "        domain = [0]\n",
    "        domainScaling = [0]\n",
    "        domainOffset = [0]\n",
    "        mlLocal.export_trees_to_fc_CCRS(trees,response,regressors,regressorsGEECollectionName,regressorsGEENames,regressorsGEEScaling2,regressorsGEEScaling,regressorsGEEOffset,domain,domainScaling,domainOffset,assetID)\n",
    "        # ee_classifier = strings_to_classifier(trees)\n",
    "        # print(ee_classifier.getInfo())\n",
    "    print(childSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5c24800-6d83-4554-bc54-de55b6d7bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only run this is you want to delete all GEE assets in a folder\n",
    "# for asset in get_asset_list('projects/ee-modis250/assets/FTL_trees_LAI'):\n",
    "#     ee.data.deleteAsset(asset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
